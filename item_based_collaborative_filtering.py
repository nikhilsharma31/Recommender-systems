# -*- coding: utf-8 -*-
"""Item based collaborative filtering.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1b7ae4dbd8VFMntwDeuKb-2JCXhvzXaFa

## Item Based Collaborative Filtering Recommender System
"""

import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

"""Loading u.info -> The number of users, items, and ratings in the MovieLens dataset"""

data_info = pd.read_csv('u.info', header=None)
list(data_info[0])

"""Loading u.data -> A dataset comprising user id, movie id, rating and timestamp"""

column_names = ['user id','movie id','rating','timestamp']
u_data = pd.read_csv('u.data', sep='\t',header=None,names=column_names)
print(len(u_data))
u_data.head()

"""Loading u.item -> Dataset comprising movie id, movie title, release date, IMDb URL and 19 fields of genre (1 indicates the movie is of that genre, a 0 indicates it is not)"""

c = 'movie id | movie title | release date | video release date | IMDb URL | unknown | Action | Adventure | Animation | Children | Comedy | Crime | Documentary | Drama | Fantasy | Film-Noir | Horror | Musical | Mystery | Romance | Sci-Fi | Thriller | War | Western'
column_names2 = c.split(' | ')
column_names2

data_items = pd.read_csv('u.item', sep='|',header=None,names=column_names2,encoding='latin-1')
data_items

"""Merging u.data and u.items"""

merged_data = pd.merge(u_data, data_items[['movie id', 'movie title']], how='left', left_on='movie id', right_on='movie id')
print(len(merged_data))
print(merged_data)

"""There is an issue with this dataset that for the same set of user id and movie id, ratings can be different at different timestamps. Example of such duplicates are shown below:-"""

duplicates = merged_data[merged_data.duplicated(['user id', 'movie title', 'rating'], keep=False)]
duplicates

"""Therefore a dataset is created from the existing merged dataset by grouping the unique user id and movie title combination and the ratings by a user to the same movie in different instances (timestamps) are averaged and stored in the new dataset."""

dataset = merged_data.groupby(by=['user id','movie title'], as_index=False).agg({"rating":"mean"})
print(len(dataset))
dataset.head()

""" # Training KNN model to build item-based collaborative Recommender System.

 Reshaping model in such a way that each user has n-dimensional rating space where n is total number of movies

We will train the KNN model in order to find the closely matching similar users to the user we give as input and we recommend the top movies which would interest the input user.
"""

user_to_movie_dataset = dataset.pivot(
    index='user id',
     columns='movie title',
      values='rating').fillna(0)

user_to_movie_dataset

"""This user to movie dataset is converted to a scipy sparse matrix using the csr_matrix of the submodule scipy.sparse within the SciPy library. This is done as here we are dealing with a large and sparse matrix and a csr_matrix can offer significant memory and computational efficiency. Sparse matrices are a more memory-efficient representation for datasets where the majority of the elements are zero.

In a sparse matrix, only non-zero elements are stored along with their indices, while zero elements are implicitly assumed and not stored. This can lead to substantial savings in terms of memory usage, which is crucial when working with large datasets, such as user-item interaction matrices in collaborative filtering for recommendation systems.
"""

from scipy.sparse import csr_matrix
user_to_movie_sparse_df = csr_matrix(user_to_movie_dataset.values)
user_to_movie_sparse_df

"""Fitting K-Nearest Neighbours model to the scipy sparse matrix:"""

from sklearn.neighbors import NearestNeighbors
knn_model = NearestNeighbors(metric='cosine', algorithm='brute')
knn_model.fit(user_to_movie_sparse_df)

""" Function to find top n similar users of the given input user:-"""

def get_neighbours(user, n = 5):
  knn_input = np.asarray([user_to_movie_dataset.values[user-1]])
  distances, indices = knn_model.kneighbors(knn_input, n_neighbors=n+1)
  distances= distances.reshape(n+1,)
  indices= indices.reshape(n+1,)
  print("Top",n,"users who are similar to the User-",user, "are: ")
  print(" ")
  for i in range(1,len(distances)):
    print(i,". User:", indices[i]+1, "separated by distance of",distances[i])
  return indices[1:] + 1, distances[1:]

user_id = 324
print(" Few of the movies seen by the User:")
print(list(dataset[dataset['user id'] == user_id]['movie title'])[:10])
print("")
similar_users, distance_of_similar_users = get_neighbours(user_id,5)

similar_users, distance_of_similar_users

weights = distance_of_similar_users/np.sum(distance_of_similar_users)
print(weights)

rating_of_similar_users= user_to_movie_dataset.values[similar_users]
print(rating_of_similar_users)

all_movies = user_to_movie_dataset.columns
all_movies

weights = weights[:,np.newaxis] + np.zeros(len(all_movies))
weights=weights.reshape(5,1664)
weights

"""To built an efficient model, we take weighted ratings of movies which is used for recommendation of movies to the input user"""

weighted_ratings = weights*rating_of_similar_users
print(weighted_ratings)
mean_weighted_ratings_of_all_movies = weighted_ratings.sum(axis =0)
print(mean_weighted_ratings_of_all_movies)

"""The mean weighted rating matrix can be used for recommendation but these set of recommended movies might contain the movies which the user has already seen so we are required to remove such movies from recommender list"""

def movie_recommendations(n):

  last_zero_index = np.where(mean_weighted_ratings_of_all_movies == 0)[0][-1] # last index of zero rating in the weighted rating list
  sorted_indices = np.argsort(mean_weighted_ratings_of_all_movies)[::-1] # list of the sorted indices in descending order of the ratings
  sorted_indices = sorted_indices[:list(sorted_indices).index(last_zero_index)] # extracting indices for non-zero mean ratings
  n = min(len(sorted_indices),n)
  all_movies_watched_by_user = list(dataset[dataset['user id'] == user_id]['movie title']) # all movies watched by the user
  filtered_movie_list = list(all_movies[sorted_indices]) # list of all the movies whose mean ratings are non-zero
  count = 0
  recommended_movies = []
  for i in filtered_movie_list:
    if i not in all_movies_watched_by_user:
      count+=1
      recommended_movies.append(i)
    if count == n:
      break
  if count == 0:
    print("There are no movies left which are not seen by the input users and seen by similar users. May be increasing the number of similar users who are to be considered may give a chance of suggesting an unseen good movie.")
  else:
    print(recommended_movies)

movie_recommendations(10)